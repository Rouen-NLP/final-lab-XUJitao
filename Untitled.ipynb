{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Memo', 'Advertisement', 'Scientific', 'Letter', 'News', 'Note', 'Report', 'Form', 'Email', 'Resume']\n",
      "['620', '230', '261', '567', '188', '201', '265', '431', '599', '120']\n"
     ]
    }
   ],
   "source": [
    "base_data_dir = \"data/Tobacco3482-OCR/\"\n",
    "list_dir = os.listdir(base_data_dir)\n",
    "print(str(list_dir))\n",
    "nbs = []\n",
    "x = []\n",
    "y = []\n",
    "for repo in list_dir:\n",
    "    prefix = base_data_dir + repo + '/'\n",
    "    files = os.listdir(prefix)\n",
    "    for file in files:\n",
    "        with open(prefix + file, 'r') as f:\n",
    "            txt = f.read()\n",
    "        x.append(txt)\n",
    "        y.append(repo)\n",
    "    nbs.append(str(len(files)))\n",
    "print(str(nbs))\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x.shape[0]):\n",
    "    x[i] = x[i].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('tobacco_train.txt', 'w') as f:\n",
    "    for i in range(x_train.shape[0]):\n",
    "        line = x_train[i] + ' __label__' + y_train[i] + '\\n'\n",
    "        f.write(line)\n",
    "with open('tobacco_test.txt', 'w') as f:\n",
    "    for i in range(x_test.shape[0]):\n",
    "        line = x_test[i] + ' __label__' + y_test[i] + '\\n'\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Memo'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SLevrillard  MEMORANDUM September 24, 1993 TO: W. R. Deaton FROM: E. F. DeLaura RE: Panel Results: Harley Lights 100 MM R&D #1385-6/93  Attached are the Low Tar panel results for The Harley Lights V 1OOMM proto.  Results for the previously reported Harley Lights V 85 MM and the Regular brand are also shown as a source of  reference.  Just to note, the Regular brand testing in which these Low Tar NM panel members tested their own brand blinded, will serve as benchmark data in this and subsequent/panel memos.  The Regular brand results represent the \"ideal ratings\" as most respondents were extremely favorable in their  evaluations for their regular brand (in test).  Product Specs are as follows:  Harley Lts. 100 MM 9.8 mgs. tar -71 mgs. nic. Harley Lts. 85 MM 8.5 mgs. tar .66 mgs. nic. Conclusions  The Harley Lts. 100 MM proto (1385-6-93) attained an average acceptance of 6.5 among total respondents. While the product scored well among 100 MM and smokers 30 years of age and over, it netted out poorly with the 85 MM smokers and  those 18 to 29 years of age.  The 85 MM proto (1592/93-93) fared better in total, 6.8, and among all sub groups. Of note is how the 18-29 year old smokers rated all three products the lowest of all the  sub-groups. (See Table 1)  Product Performance Total Smokers  The key problem with Harley Lts. 100 MM is its \"too light/not strong enough\" taste. It was not cited as overly harsh tasting or having an unpleasant aftertaste.  (See Table 2)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "texts = []\n",
    "clf = fasttext.supervised('tobacco_train.txt', 'model')\n",
    "with open('tobacco_train.txt') as f:\n",
    "    for line in f:\n",
    "        spli = line.split(\"__label__\")\n",
    "        true_labels.append(spli[1].replace(\"\\n\", \"\"))\n",
    "        texts.append(spli[0])\n",
    "pred_labels = [e[0] for e in clf.predict(texts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-68eca705d984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix, without normalization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = np.unique(true_labels)\n",
    "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plot_confusion_matrix(conf_mat, class_names, title='Confusion matrix, without normalization')\n",
    "plt.subplot(122)\n",
    "plot_confusion_matrix(conf_mat, class_names, normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
